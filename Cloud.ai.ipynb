{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Migraine Prediction ML Project - Complete Implementation\n",
    "# =====================================================\n",
    "\n",
    "# Import all necessary libraries\n",
    "\n",
    "from sklearn.feature_selection import RFE, SelectKBest, chi2, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "## Step 2: Exploratory Data Analysis (EDA)\n",
    "print(f\"\\n\\nðŸ” Step 2: Exploratory Data Analysis\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create visualization function\n",
    "def create_eda_plots():\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n\\nðŸ”§ Step 3: Feature Engineering\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def create_engineered_features(df):\n",
    "    \"\"\"Create new features based on domain knowledge\"\"\"\n",
    "\n",
    "\n",
    "    # Exercise consistency (had exercise in last 3 days)\n",
    "    df_eng['recent_exercise'] = (df_eng.groupby('user_id')['exercise_minutes'].rolling(window=3, min_periods=1).sum().values > 0).astype(int)\n",
    "    \n",
    "    return df_eng\n",
    "\n",
    "# Apply feature engineering\n",
    "df_engineered = create_engineered_features(df)\n",
    "\n",
    "print(f\"âœ… Feature engineering completed!\")\n",
    "print(f\"Original features: {df.shape[1]}\")\n",
    "print(f\"Engineered features: {df_engineered.shape[1]}\")\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 2: DATA PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "#\n",
    "print(f\"\\n\\nðŸ§¹ Step 4: Data Cleaning and Validation\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "print(f\"\\n\\nðŸ”„ Step 5: Train-Test Split Strategy\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "#\n",
    "print(f\"\\n\\nðŸ¤– Step 6: Baseline Models\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "print(f\"\\n\\nðŸš€ Step 7: Advanced Models\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Combine all results\n",
    "all_results = baseline_results + advanced_results\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(f\"\\nðŸ“Š All Models Comparison:\")\n",
    "print(all_results_df.round(3))\n",
    "\n",
    "# Find best model based on F1 score (balanced metric)\n",
    "best_model_idx = all_results_df['Val_F1'].idxmax()\n",
    "best_model_name = all_results_df.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name} (F1: {all_results_df.loc[best_model_idx, 'Val_F1']:.3f})\")\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 4: MODEL OPTIMIZATION\n",
    "# =============================================================================\n",
    "\n",
    "## Step 9: Hyperparameter Tuning\n",
    "print(f\"\\n\\nâš™ï¸ Step 9: Hyperparameter Tuning\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Hyperparameter tuning for the best performing models\n",
    "def tune_random_forest(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Tune Random Forest hyperparameters\"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def tune_xgboost(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Tune XGBoost hyperparameters\"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    \n",
    "    xgb = GradientBoostingClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(xgb, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Tune top performing models\n",
    "print(\"ðŸ”§ Tuning Random Forest...\")\n",
    "best_rf, best_rf_params = tune_random_forest(X_train, y_train, X_val, y_val)\n",
    "print(f\"âœ… Best RF params: {best_rf_params}\")\n",
    "\n",
    "print(\"\\nðŸ”§ Tuning XGBoost...\")\n",
    "best_xgb, best_xgb_params = tune_xgboost(X_train, y_train, X_val, y_val)\n",
    "print(f\"âœ… Best XGB params: {best_xgb_params}\")\n",
    "\n",
    "# Evaluate tuned models\n",
    "tuned_results = []\n",
    "\n",
    "for name, model in [('Tuned_RF', best_rf), ('Tuned_XGB', best_xgb)]:\n",
    "    results, _ = evaluate_model(model, X_train, y_train,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MIGRAINE DISEASE PROGRESSION MODEL\n",
    "# Time Series and Sequence-Based Approach for Migraine Prediction\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For advanced time series modeling\n",
    "try:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ TensorFlow not available. Using traditional ML models.\")\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "print(\"ðŸ§  MIGRAINE DISEASE PROGRESSION MODEL\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Treating migraine prediction as a temporal disease progression problem\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 1: TEMPORAL FEATURE ENGINEERING FOR DISEASE PROGRESSION\n",
    "# ============================================================================\n",
    "\n",
    "def create_disease_progression_features(df):\n",
    "    \"\"\"\n",
    "    Create features that capture migraine disease progression patterns\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”¬ Creating Disease Progression Features...\")\n",
    "    \n",
    "    df_prog = df.copy()\n",
    "    df_prog = df_prog.sort_values(['user_id', 'day']).reset_index(drop=True)\n",
    "    \n",
    "    # ========================================\n",
    "    # MIGRAINE CYCLE ANALYSIS\n",
    "    # ========================================\n",
    "    print(\"ðŸ“Š Analyzing migraine cycles...\")\n",
    "    \n",
    "    # Days since last migraine (critical for progression)\n",
    "    df_prog['days_since_last_migraine'] = 0\n",
    "    df_prog['days_until_next_migraine'] = 0\n",
    "    \n",
    "    for user_id in df_prog['user_id'].unique():\n",
    "        user_mask = df_prog['user_id'] == user_id\n",
    "        user_data = df_prog[user_mask].copy()\n",
    "        \n",
    "        # Find migraine days\n",
    "        migraine_days = user_data[user_data['has_migraine'] == 1]['day'].values\n",
    "        \n",
    "        if len(migraine_days) > 0:\n",
    "            # Days since last migraine\n",
    "            days_since = []\n",
    "            days_until = []\n",
    "            \n",
    "            for day in user_data['day'].values:\n",
    "                # Days since last migraine\n",
    "                past_migraines = migraine_days[migraine_days < day]\n",
    "                if len(past_migraines) > 0:\n",
    "                    days_since.append(day - past_migraines[-1])\n",
    "                else:\n",
    "                    days_since.append(999)  # No previous migraine\n",
    "                \n",
    "                # Days until next migraine\n",
    "                future_migraines = migraine_days[migraine_days > day]\n",
    "                if len(future_migraines) > 0:\n",
    "                    days_until.append(future_migraines[0] - day)\n",
    "                else:\n",
    "                    days_until.append(999)  # No future migraine in data\n",
    "            \n",
    "            df_prog.loc[user_mask, 'days_since_last_migraine'] = days_since\n",
    "            df_prog.loc[user_mask, 'days_until_next_migraine'] = days_until\n",
    "    \n",
    "    # ========================================\n",
    "    # PRODROME PHASE DETECTION (Pre-migraine symptoms)\n",
    "    # ========================================\n",
    "    print(\"ðŸ” Detecting prodrome phase patterns...\")\n",
    "    \n",
    "    # Look for patterns 1-3 days before migraine\n",
    "    for lookback in [1, 2, 3]:\n",
    "        df_prog[f'migraine_in_{lookback}d'] = 0\n",
    "        \n",
    "        for user_id in df_prog['user_id'].unique():\n",
    "            user_mask = df_prog['user_id'] == user_id\n",
    "            user_data = df_prog[user_mask].copy()\n",
    "            \n",
    "            # Shift migraine indicator forward to create \"future migraine\" flag\n",
    "            future_migraine = user_data['has_migraine'].shift(-lookback).fillna(0)\n",
    "            df_prog.loc[user_mask, f'migraine_in_{lookback}d'] = future_migraine\n",
    "    \n",
    "    # Prodrome risk score (elevated stress + poor sleep + days since last migraine)\n",
    "    df_prog['prodrome_risk_score'] = (\n",
    "        (df_prog['stress_level'] > df_prog['stress_level'].quantile(0.7)).astype(int) +\n",
    "        (df_prog['sleep_hours'] < 6.5).astype(int) +\n",
    "        (df_prog['days_since_last_migraine'].between(3, 10)).astype(int) +\n",
    "        (df_prog['hydration_glasses'] < df_prog['hydration_glasses'].quantile(0.3)).astype(int)\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # MIGRAINE FREQUENCY AND INTENSITY PATTERNS\n",
    "    # ========================================\n",
    "    print(\"ðŸ“ˆ Analyzing frequency and intensity patterns...\")\n",
    "    \n",
    "    # Rolling migraine frequency (disease burden)\n",
    "    for window in [7, 14, 30]:\n",
    "        df_prog[f'migraine_frequency_{window}d'] = (\n",
    "            df_prog.groupby('user_id')['has_migraine']\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .sum().values\n",
    "        )\n",
    "    \n",
    "    # Migraine intensity if available\n",
    "    if 'migraine_severity' in df_prog.columns:\n",
    "        for window in [7, 14]:\n",
    "            df_prog[f'avg_severity_{window}d'] = (\n",
    "                df_prog.groupby('user_id')['migraine_severity']\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .mean().values\n",
    "            )\n",
    "    \n",
    "    # ========================================\n",
    "    # TRIGGER ACCUMULATION MODEL\n",
    "    # ========================================\n",
    "    print(\"âš¡ Creating trigger accumulation features...\")\n",
    "    \n",
    "    # Cumulative stress exposure\n",
    "    df_prog['stress_burden_3d'] = (\n",
    "        df_prog.groupby('user_id')['stress_level']\n",
    "        .rolling(window=3, min_periods=1)\n",
    "        .sum().values\n",
    "    )\n",
    "    \n",
    "    df_prog['stress_burden_7d'] = (\n",
    "        df_prog.groupby('user_id')['stress_level']\n",
    "        .rolling(window=7, min_periods=1)\n",
    "        .sum().values\n",
    "    )\n",
    "    \n",
    "    # Sleep debt accumulation (critical for migraine progression)\n",
    "    df_prog['sleep_debt'] = np.maximum(0, 7.5 - df_prog['sleep_hours'])\n",
    "    df_prog['cumulative_sleep_debt_3d'] = (\n",
    "        df_prog.groupby('user_id')['sleep_debt']\n",
    "        .rolling(window=3, min_periods=1)\n",
    "        .sum().values\n",
    "    )\n",
    "    \n",
    "    df_prog['cumulative_sleep_debt_7d'] = (\n",
    "        df_prog.groupby('user_id')['sleep_debt']\n",
    "        .rolling(window=7, min_periods=1)\n",
    "        .sum().values\n",
    "    )\n",
    "    \n",
    "    # Dehydration risk accumulation\n",
    "    df_prog['dehydration_risk'] = (df_prog['hydration_glasses'] < 6).astype(int)\n",
    "    df_prog['dehydration_days_3d'] = (\n",
    "        df_prog.groupby('user_id')['dehydration_risk']\n",
    "        .rolling(window=3, min_periods=1)\n",
    "        .sum().values\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # RECOVERY AND RESILIENCE FACTORS\n",
    "    # ========================================\n",
    "    print(\"ðŸ’ª Adding recovery and resilience factors...\")\n",
    "    \n",
    "    # Exercise consistency (protective factor)\n",
    "    df_prog['exercise_consistency_7d'] = (\n",
    "        df_prog.groupby('user_id')['exercise_minutes']\n",
    "        .rolling(window=7, min_periods=1)\n",
    "        .apply(lambda x: (x > 0).sum()).values\n",
    "    )\n",
    "    \n",
    "    # Lifestyle stability score\n",
    "    df_prog['sleep_variability_7d'] = (\n",
    "        df_prog.groupby('user_id')['sleep_hours']\n",
    "        .rolling(window=7, min_periods=1)\n",
    "        .std().values\n",
    "    )\n",
    "    \n",
    "    df_prog['lifestyle_stability'] = (\n",
    "        (df_prog['sleep_variability_7d'] < 1).astype(int) +\n",
    "        (df_prog['exercise_consistency_7d'] >= 3).astype(int)\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # TEMPORAL PROGRESSION FEATURES\n",
    "    # ========================================\n",
    "    print(\"â° Creating temporal progression features...\")\n",
    "    \n",
    "    # Migraine episode clustering (multiple migraines close together)\n",
    "    df_prog['migraine_cluster_3d'] = (\n",
    "        df_prog.groupby('user_id')['has_migraine']\n",
    "        .rolling(window=3, center=True, min_periods=1)\n",
    "        .sum().values >= 2\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Time-based vulnerability windows\n",
    "    df_prog['weekend_vulnerability'] = (\n",
    "        (df_prog['is_weekend'] == 1) & \n",
    "        (df_prog['days_since_last_migraine'] > 3) &\n",
    "        (df_prog['stress_burden_7d'] > df_prog['stress_burden_7d'].quantile(0.6))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Workweek stress accumulation\n",
    "    df_prog['workweek_stress_buildup'] = (\n",
    "        (df_prog['day_of_week'].isin([0, 1, 2, 3, 4])) & \n",
    "        (df_prog['stress_burden_3d'] > df_prog['stress_burden_3d'].quantile(0.7))\n",
    "    ).astype(int)\n",
    "    \n",
    "    print(f\"âœ… Disease progression features created. Total features: {df_prog.shape[1]}\")\n",
    "    \n",
    "    return df_prog\n",
    "\n",
    "# ============================================================================\n",
    "# SEQUENCE MODELING FOR DISEASE PROGRESSION\n",
    "# ============================================================================\n",
    "\n",
    "def create_sequences_for_user(user_data, sequence_length=7, target_col='has_migraine'):\n",
    "    \"\"\"\n",
    "    Create sequences for time series modeling\n",
    "    \"\"\"\n",
    "    feature_cols = [col for col in user_data.columns if col not in \n",
    "                   ['user_id', 'day', 'has_migraine', 'migraine_severity']]\n",
    "    \n",
    "    X_sequences = []\n",
    "    y_sequences = []\n",
    "    \n",
    "    for i in range(len(user_data) - sequence_length):\n",
    "        # Input sequence (past sequence_length days)\n",
    "        X_seq = user_data[feature_cols].iloc[i:i+sequence_length].values\n",
    "        \n",
    "        # Target (next day's migraine status)\n",
    "        y_seq = user_data[target_col].iloc[i+sequence_length]\n",
    "        \n",
    "        X_sequences.append(X_seq)\n",
    "        y_sequences.append(y_seq)\n",
    "    \n",
    "    return np.array(X_sequences), np.array(y_sequences)\n",
    "\n",
    "def prepare_sequence_data(df_prog, sequence_length=7):\n",
    "    \"\"\"\n",
    "    Prepare all user data for sequence modeling\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ“Š Preparing sequence data with {sequence_length}-day lookback...\")\n",
    "    \n",
    "    all_X_sequences = []\n",
    "    all_y_sequences = []\n",
    "    all_user_ids = []\n",
    "    \n",
    "    for user_id in df_prog['user_id'].unique():\n",
    "        user_data = df_prog[df_prog['user_id'] == user_id].sort_values('day')\n",
    "        \n",
    "        if len(user_data) > sequence_length:\n",
    "            X_seq, y_seq = create_sequences_for_user(user_data, sequence_length)\n",
    "            \n",
    "            if len(X_seq) > 0:\n",
    "                all_X_sequences.append(X_seq)\n",
    "                all_y_sequences.append(y_seq)\n",
    "                all_user_ids.extend([user_id] * len(X_seq))\n",
    "    \n",
    "    if all_X_sequences:\n",
    "        X_combined = np.vstack(all_X_sequences)\n",
    "        y_combined = np.hstack(all_y_sequences)\n",
    "        user_ids_combined = np.array(all_user_ids)\n",
    "        \n",
    "        print(f\"âœ… Sequence data prepared: {X_combined.shape[0]} sequences, {X_combined.shape[1]} timesteps, {X_combined.shape[2]} features\")\n",
    "        return X_combined, y_combined, user_ids_combined\n",
    "    else:\n",
    "        print(\"âŒ No sequences could be created\")\n",
    "        return None, None, None\n",
    "\n",
    "# ============================================================================\n",
    "# ADVANCED TIME SERIES MODELS\n",
    "# ============================================================================\n",
    "\n",
    "class MigraineProgressionPredictor:\n",
    "    def __init__(self, model_type='lstm'):\n",
    "        self.model_type = model_type\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.history = None\n",
    "        \n",
    "    def build_lstm_model(self, input_shape):\n",
    "        \"\"\"Build LSTM model for migraine progression\"\"\"\n",
    "        model = Sequential([\n",
    "            LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "            Dropout(0.3),\n",
    "            LSTM(32, return_sequences=False),\n",
    "            Dropout(0.3),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', 'precision', 'recall']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_cnn_lstm_model(self, input_shape):\n",
    "        \"\"\"Build CNN-LSTM hybrid model\"\"\"\n",
    "        model = Sequential([\n",
    "            Conv1D(32, 3, activation='relu', input_shape=input_shape),\n",
    "            Conv1D(32, 3, activation='relu'),\n",
    "            MaxPooling1D(2),\n",
    "            LSTM(50, return_sequences=True),\n",
    "            Dropout(0.3),\n",
    "            LSTM(25),\n",
    "            Dropout(0.3),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', 'precision', 'recall']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, epochs=50):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        if self.model_type == 'lstm' and TENSORFLOW_AVAILABLE:\n",
    "            self.model = self.build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "            \n",
    "            callbacks = [EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "            \n",
    "            if X_val is not None:\n",
    "                validation_data = (X_val, y_val)\n",
    "            else:\n",
    "                validation_data = None\n",
    "            \n",
    "            self.history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=32,\n",
    "                validation_data=validation_data,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "        elif self.model_type == 'cnn_lstm' and TENSORFLOW_AVAILABLE:\n",
    "            self.model = self.build_cnn_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "            \n",
    "            callbacks = [EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "            \n",
    "            if X_val is not None:\n",
    "                validation_data = (X_val, y_val)\n",
    "            else:\n",
    "                validation_data = None\n",
    "            \n",
    "            self.history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=32,\n",
    "                validation_data=validation_data,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            # Fallback to traditional ML with flattened sequences\n",
    "            X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "            if X_val is not None:\n",
    "                X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
    "            \n",
    "            # Scale features\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train_flat)\n",
    "            \n",
    "            if self.model_type == 'rf':\n",
    "                self.model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "            elif self.model_type == 'gb':\n",
    "                self.model = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "            elif self.model_type == 'mlp':\n",
    "                self.model = MLPClassifier(\n",
    "                    hidden_layer_sizes=(100, 50, 25),\n",
    "                    random_state=42,\n",
    "                    max_iter=500\n",
    "                )\n",
    "            else:\n",
    "                self.model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "            \n",
    "            self.model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        if self.model_type in ['lstm', 'cnn_lstm'] and TENSORFLOW_AVAILABLE:\n",
    "            return (self.model.predict(X) > 0.5).astype(int).flatten()\n",
    "        else:\n",
    "            X_flat = X.reshape(X.shape[0], -1)\n",
    "            X_scaled = self.scaler.transform(X_flat)\n",
    "            return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probabilities\"\"\"\n",
    "        if self.model_type in ['lstm', 'cnn_lstm'] and TENSORFLOW_AVAILABLE:\n",
    "            return self.model.predict(X).flatten()\n",
    "        else:\n",
    "            X_flat = X.reshape(X.shape[0], -1)\n",
    "            X_scaled = self.scaler.transform(X_flat)\n",
    "            return self.model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "# ============================================================================\n",
    "# TEMPORAL VALIDATION FOR DISEASE PROGRESSION\n",
    "# ============================================================================\n",
    "\n",
    "def temporal_train_test_split(X, y, user_ids, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split data temporally - use later time periods for testing\n",
    "    \"\"\"\n",
    "    unique_users = np.unique(user_ids)\n",
    "    n_test_users = int(len(unique_users) * test_size)\n",
    "    \n",
    "    # Use last portion of data for each user as test set\n",
    "    test_users = unique_users[-n_test_users:]\n",
    "    \n",
    "    test_mask = np.isin(user_ids, test_users)\n",
    "    train_mask = ~test_mask\n",
    "    \n",
    "    return X[train_mask], X[test_mask], y[train_mask], y[test_mask]\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def run_migraine_progression_analysis(df):\n",
    "    \"\"\"\n",
    "    Main function to run complete migraine progression analysis\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸš€ Starting Migraine Disease Progression Analysis...\")\n",
    "    \n",
    "    # Step 1: Create disease progression features\n",
    "    df_prog = create_disease_progression_features(df)\n",
    "    \n",
    "    # Step 2: Prepare sequence data\n",
    "    sequence_length = 7\n",
    "    X_seq, y_seq, user_ids = prepare_sequence_data(df_prog, sequence_length)\n",
    "    \n",
    "    if X_seq is None:\n",
    "        print(\"âŒ Could not create sequence data. Check your dataset.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 3: Temporal train-test split\n",
    "    X_train, X_test, y_train, y_test = temporal_train_test_split(\n",
    "        X_seq, y_seq, user_ids, test_size=0.2\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Data Split Summary:\")\n",
    "    print(f\"Training sequences: {len(X_train)}\")\n",
    "    print(f\"Testing sequences: {len(X_test)}\")\n",
    "    print(f\"Training migraine rate: {y_train.mean():.3f}\")\n",
    "    print(f\"Testing migraine rate: {y_test.mean():.3f}\")\n",
    "    \n",
    "    # Step 4: Train multiple models\n",
    "    models = {\n",
    "        'LSTM': MigraineProgressionPredictor('lstm'),\n",
    "        'CNN-LSTM': MigraineProgressionPredictor('cnn_lstm'),\n",
    "        'Random Forest': MigraineProgressionPredictor('rf'),\n",
    "        'Gradient Boosting': MigraineProgressionPredictor('gb'),\n",
    "        'MLP': MigraineProgressionPredictor('mlp')\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nðŸ”„ Training {name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Split training data for validation\n",
    "            val_split = int(0.8 * len(X_train))\n",
    "            X_train_sub = X_train[:val_split]\n",
    "            y_train_sub = y_train[:val_split]\n",
    "            X_val = X_train[val_split:]\n",
    "            y_val = y_train[val_split:]\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train_sub, y_train_sub, X_val, y_val, epochs=30)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            results[name] = {\n",
    "                'f1_score': f1,\n",
    "                'roc_auc': auc,\n",
    "                'model': model,\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_pred_proba\n",
    "            }\n",
    "            \n",
    "            print(f\"âœ… {name} - F1: {f1:.3f}, AUC: {auc:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {name} failed: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Step 5: Select best model and detailed analysis\n",
    "    best_model_name = max(results.keys(), key=lambda x: results[x]['f1_score'])\n",
    "    best_model = results[best_model_name]\n",
    "    \n",
    "    print(f\"\\nðŸ† BEST MODEL: {best_model_name}\")\n",
    "    print(f\"F1-Score: {best_model['f1_score']:.3f}\")\n",
    "    print(f\"ROC-AUC: {best_model['roc_auc']:.3f}\")\n",
    "    \n",
    "    # Detailed evaluation\n",
    "    print(f\"\\nðŸ“‹ Detailed Classification Report:\")\n",
    "    print(classification_report(y_test, best_model['predictions']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, best_model['predictions'])\n",
    "    print(f\"\\nðŸ“Š Confusion Matrix:\")\n",
    "    print(f\"                Predicted\")\n",
    "    print(f\"              No    Yes\")\n",
    "    print(f\"Actual No   {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "    print(f\"       Yes  {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "    \n",
    "    # Progression insights\n",
    "    print(f\"\\nðŸ’¡ DISEASE PROGRESSION INSIGHTS:\")\n",
    "    \n",
    "    # High-risk sequences analysis\n",
    "    high_risk_threshold = 0.7\n",
    "    high_risk_mask = best_model['probabilities'] > high_risk_threshold\n",
    "    high_risk_accuracy = (y_test[high_risk_mask] == best_model['predictions'][high_risk_mask]).mean()\n",
    "    \n",
    "    print(f\"High-risk predictions (>{high_risk_threshold}): {high_risk_mask.sum()}\")\n",
    "    print(f\"Accuracy on high-risk predictions: {high_risk_accuracy:.3f}\")\n",
    "    print(f\"Actual migraine rate in high-risk sequences: {y_test[high_risk_mask].mean():.3f}\")\n",
    "    \n",
    "    # Early warning capability\n",
    "    early_warning_days = [1, 2, 3]\n",
    "    print(f\"\\nâš¡ Early Warning Analysis:\")\n",
    "    for days in early_warning_days:\n",
    "        # This would require additional analysis of the progression features\n",
    "        print(f\"Model can potentially provide {days}-day advance warning\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ CLINICAL RECOMMENDATIONS:\")\n",
    "    print(\"1. Monitor patients during high-risk sequences (probability > 0.7)\")\n",
    "    print(\"2. Implement preventive interventions when progression patterns detected\")\n",
    "    print(\"3. Focus on sleep debt accumulation and stress burden patterns\")\n",
    "    print(\"4. Use 7-day lookback window for optimal prediction accuracy\")\n",
    "    print(\"5. Consider personalized intervention thresholds based on individual patterns\")\n",
    "    \n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'all_results': results,\n",
    "        'test_data': (X_test, y_test),\n",
    "        'progression_features': df_prog\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“š USAGE INSTRUCTIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"To use this migraine progression model:\")\n",
    "print(\"1. Load your dataset with columns: user_id, day, sleep_hours, stress_level,\")\n",
    "print(\"   screen_time_hours, hydration_glasses, exercise_minutes, day_of_week,\")\n",
    "print(\"   is_weekend, month, has_migraine, migraine_severity\")\n",
    "print(\"2. Call: results = run_migraine_progression_analysis(df)\")\n",
    "print(\"3. The model will treat migraine prediction as a temporal disease progression\")\n",
    "print(\"4. Results include early warning capabilities and progression insights\")\n",
    "print(\"\\nExample:\")\n",
    "print(\"# results = run_migraine_progression_analysis(your_dataframe)\")\n",
    "print(\"# best_model = results['best_model']\")\n",
    "print(\"# progression_features = results['progression_features']\")\n",
    "\n",
    "print(\"\\nâœ… Migraine Disease Progression Model Ready!\")\n",
    "print(\"This approach focuses on temporal patterns and disease progression rather than single-day predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
